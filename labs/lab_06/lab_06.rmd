---
title: "lab_06"
author: "derek willis"
date: "8/26/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## About this lab

To complete this lab, you need to:
* [install Tabula](https://tabula.technology/)
* run existing code as directed (look for **Task**).
* write code as directed (look for **Task**).
* write code in empty codeblocks provided to answer questions included (look for **Q**).
* write out the answer in the form of a complete sentence in the space given (look for **A**).

When you are finished, commit changes in the lab_06 folder and push to your personal GitHub repo, then submit the URL to this document on ELMS.

## Load libraries and establish settings

**Task** Run the codeblock below to load the Tidyverse. To run the codeblock, hit the little green play button in the upper right corner of the gray area (the codeblock) below.

```{r}
# Turn off scientific notation
options(scipen=999)

# Load the tidyverse.
library(tidyverse)
```

## Get Our PDF

We'll be working with the [Maryland Statistical Handbook](https://planning.maryland.gov/MSDC/Documents/md-statistical-handbook.pdf) from the state Department of Planning. It's not tiny (44MB), and you'll want to download it to a place you'll remember (like your Downloads folder).

**Task** Download the file from the above link and save it to your Downloads folder.

## Setup Tabula

**Task** Start Tabula and load the PDF, then extract a table

Start Tabula, then go to http://127.0.0.1:8080/ in your browser. Click the "Browse" button and find the Statistical Handbook file in your Downloads folder and click "open", and then click the "Import button" in Tabula. This will take a minute or two.

Let's go to page 30 of the PDF, Table 2A, "International Migration for Maryland's Jurisdictions, July 1, 2010 to July 1, 2019". This is _net migration_, meaning it shows the total number of people moving to Maryland and its regions/jurisdictions _minus_ the total number of people leaving the same, divided into 12-month periods from July to July. In Tabula, draw a box around that table's border and click the "Preview & Export Extracted Data" button. It should look pretty clean. Let's export that CSV (it should be called `tabula-md-statistical-handbook.csv` by default) to your lab_06/data folder.

## Cleaning up the data in R

Let's load it into R, and in doing so we'll skip the first two rows and add our own headers that are cleaner. `read_csv` allows us to do this ([and more](https://readr.tidyverse.org/reference/read_delim.html)):

**Task** Write code to read the CSV file into a dataframe called `international_migration`. As in the pre_lab, you may have to skip 1 or more rows and you may want to supply easier to use column names that use underscores.

```{r}
# Write the code to load the CSV file here

international_migration <-read_csv("tabula-md-statistical-handbook.csv" , skip=1, col_names=c("state_jurisdiction", "July10_July11","July11_July12", "July12_July13","July13_July14", "July14_July15", "July15_July16", "July16_July17", "July17_July18", "July18_July19", "July10_July19"))


```

Add a column for the type of migration ("international") and populate it:

**Task** Write the code to add a `migration_type` column to the data and populate it with the value of "international"

```{r}
# Write the code to add the column here


international_migration <- international_migration %>%
  mutate(
    migration_type = "international" 
  )


```

## Answer questions

**Q1** Which region and county/city below the state level accounted for the largest percentage of international migration overall?  You'll need to add and populate columns representing percent of total using `mutate`.
**A1** [write your answer here]

```{r}
# Write the code to produce your answer here


international_migration <- international_migration %>%
  mutate(
    percent_total = (July10_July19/198996) *100
  )

```

**Q2** Write a sentence or two that describes the data you produced in A1. Try to convey the most important idea.
**A2** [write your answer here] The suburban Washington area, which includes Baltimore, Montgomery and Prince George's counties, have seen the highest levels of international migration. Baltimore City was also in the top for migration levels, which is telling about the regions' changing socio-economic landscape. 

**Q3** Which region & jurisdiction had the biggest percentage change for international migration between July 2018 and July 2017? The formula for percentage change is easy to remember: (New-Old)/Old.
**A3** [write your answer here] Kent had the biggest percentage change. 

```{r}
# Write the code to produce your answer here

international_migration %>%
  group_by(state_jurisdiction) %>%
  summarise(percent_change =sum((July17_July18-July16_July17)/July16_July17) *100) %>%
  arrange(desc(percent_change))

```

**Q4** What's your best guess as to why these declines occurred, and in those area in particular?
**A4** [write your answer here] I think it makes sense that the urban, industrial areas of MD grew in population since there are more resources (jobs, healthcare, stable internet, etc) and migration to rural areas that can lack access to reliable  modern-day resources. 


## Back to Tabula

**Task** Extract second table from Tabula

Let's go to page 31 of the PDF, Table 2B, "Domestic Migration for Maryland's Jurisdictions, July 1, 2010 to July 1, 2019". In Tabula, hit the "Clear All Selections" button and then draw a box around that table's border and click the "Preview & Export Extracted Data" button. It should look pretty clean. Let's export that CSV to your lab_06/data folder. (and rename it to `tabula-md-statistical-handbook-domestic.csv`).

## Cleaning up the data in R

Let's load it into R, and in doing so we'll skip the first two rows and add our own headers that are cleaner:

**Task** Write code to read the CSV file into a dataframe called `domestic_migration`. As in the pre_lab, you may have to skip 1 or more rows and you may want to supply easier to use column names that use underscores. Your work on the international file should serve as a guide.

```{r}
# Write the code to load the CSV file here

domestic_migration <- read_csv("tabula-md-statistical-handbook-domestic.csv", , skip=1, col_names=c("state_jurisdiction", "July10_July11","July11_July12", "July12_July13","July13_July14", "July14_July15", "July15_July16", "July16_July17", "July17_July18", "July18_July19", "July10_July19"))
```

Add a column for the type of migration ("domestic") and populate it:

**Task** Write the code to add a `migration_type` column to the data and populate it with the value of "domestic"

```{r}
# Write the code to add the column here

domestic_migration <- domestic_migration %>%
  mutate(
    migration_type ="domestic"
  )

```

## Answer questions
**Q5** Which Maryland individual jurisdiction saw the largest net decrease in domestic migration overall?
**A5** [write your answer here] The suburban Washington Regioon saw the largest net decrease. Within this region, Balitmore city saw the highest net decrease. 

```{r}
# Write the code to produce your answer here

domestic_migration %>%
  arrange
```

**Q6** How many regions & jurisdictions had net positive migration for July 2017, July 2018 and July 2019 (not just individually but all three together)?
**A6** [write your answer here] Southern Maryland Region which includes Howard and Frederick counties and Upper Eastern Shore Region	which includes Calvert, St. Mary's, Queen Anne's, Worcester, Harford, Charles and Anne Arundel counties. 

```{r}
# Write the code to produce your answer here

domestic_migration %>% 
  filter(July16_July17 > 0, July17_July18 > 0, July18_July19 > 0) %>%
  group_by(state_jurisdiction)
  

```

**Q7** How would you describe this data? Is there a county or region that stands out, and why?
**A7** [write your answer here]

Baltimore City and Baltimore County stick out the most, which makes sense because they are basically the same place but just sightly different variations of each other. The fact that there are two Baltimore's that people can choose to move to increases its prevalence in the data. 
